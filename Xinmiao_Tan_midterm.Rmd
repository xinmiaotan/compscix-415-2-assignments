---
title: "COMPSCIX 415.2 Homework 5/Midterm"
author: "Xinmiao Tan"
date: "July 11, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

My Github repository for my assignments can be found at this URL: [https://github.com/xinmiaotan/compscix-415-2-assignments](https://github.com/xinmiaotan/compscix-415-2-assignments)


## Table of Content
### A. RStudio and R Markdown (3 points)
### B. The tidyverse packages (3 points)
### C. R Basics (1.5 points)
### D. Data import/export (3 points)
### E. Visualization (6 points)
### F. Data munging and wrangling (6 points)
### G. EDA (6 points)
### H. Git and Github (1.5 points)

------

```{r load_packages, warning=FALSE, message=FALSE}
library(tidyverse)
library(ggplot2)
```


### A. RStudio and R Markdown (3 points)
#### 1. Use markdown headers in your document to clearly separate each midterm question and add a table of contents to your document.

------


### B. The tidyverse packages (3 points)
####     1. Can you name which package is associated with each task below?

Plotting - ggplot2
Data munging/wrangling - tidyverse
Reshaping (speading and gathering) data - tidyr 
Importing/exporting data - readr


####     2. Now can you name two functions that you’ve used from each package that you listed above for these tasks?

Plotting - ggplot2:
geom_bar(), geom_point()

Data munging/wrangling - tidyverse:
group_by(), summarize()

Reshaping (speading and gathering) data - tidyr:
gather(key = , value = ), spread(key = , value = )

Importing/exporting data - readr:
write_csv(), read_csv(path = )

------


### C. R Basics (1.5 points)
####     1. Fix this code with the fewest number of changes possible so it works:

```{r}
data_name <- c( 1 , 2 , 3 )
data_name
```


####     2. Fix this code so it works:

```{r}
my_string <- c('has', 'an', 'error', 'in', 'it')
my_string
```

####     3. Look at the code below and comment on what happened to the values in the vector.

```{r}
my_vector <- c('1', '2', '3', '4', '5') 
my_vector
```

Because the vector combines both character and number. We should change all the number to character or change the character to number.


------

### D. Data import/export (3 points)

####     1. Download the rail_trail.txt file from Canvas (in the Midterm Exam section) and successfully import it into R. Prove that it was imported successfully by including your import code and taking a glimpse of the result.

```{r}
rail_trail <- read_delim(file = '/Users/xinmiaotan/Desktop/Data Science/R/IntroR/Lec5/rail_trail.txt',delim='|')
glimpse(rail_trail)
```


####     2. Export the file into a comma-separated file and name it “rail_trail.csv”. Make sure you define the path correctly so that you know where it gets saved. Then reload the file. Include your export and import code and take another glimpse.

```{r}
write_delim(rail_trail, delim=',', path = '/Users/xinmiaotan/Desktop/Data Science/R/IntroR/Lec5/rail_trail.csv')
rail_trail_csv <- read_delim(file = '/Users/xinmiaotan/Desktop/Data Science/R/IntroR/Lec5/rail_trail.csv',delim=',')
glimpse(rail_trail_csv)
```


------

### E. Visualization (6 points)

####     1. Critique this graphic: give only three examples of what is wrong with this graphic. Be concise.

1. Not easy to visualize the percentage of Yes or No, should use bar or histogram.
2. Should not put age and gender in the same figure. Should seperate them into two figures, one comparing age and other one comparing gender.
3. Should use different color for different age groups.


####     2. Reproduce this graphic using the diamonds data set.

```{r}
data(diamonds)

ggplot(data = diamonds, aes(x = cut, y = carat)) +
    geom_boxplot(aes(fill=color), position=position_dodge(width = 0), width=6) +
    coord_flip() +
    xlab('CUT OF DIAMOND') +
    ylab('CARAT OF DIAMOND')
```


####     3. The previous graphic is not very useful. We can make it much more useful by changing one thing about it. Make the change and plot it again.

```{r}
ggplot(data = diamonds, aes(x = cut, y = carat)) +
    geom_boxplot(aes(fill=color)) +
    xlab('CUT OF DIAMOND') +
    ylab('CARAT OF DIAMOND')
```


------

### F. Data munging and wrangling (6 points)

####     1. Is this data “tidy”? If yes, leave it alone and go to the next problem. If no, make it tidy. Note: this data set is called table2 and is available in the tidyverse package. It should be ready for you to use after you’ve loaded the tidyverse package.

```{r}
table2

table2_tidy <- table2 %>% spread(key = type, value = count)
table2_tidy
```


####     2. Create a new column in the diamonds data set called price_per_carat that shows the price of each diamond per carat (hint: divide). Only show me the code, not the output.

```{r}
diamonds <- diamonds %>% mutate(price_per_carat=price/carat)
```


####     3. For each cut of diamond in the diamonds data set, how many diamonds, and what proportion, have a price > 10000 and a carat < 1.5? There are several ways to get to an answer, but your solution must use the data wrangling verbs from the tidyverse in order to get credit.
####        • Do the results make sense? Why?
####        • Do we need to be wary of any of these numbers? Why?

```{r}
diamonds %>% 
    group_by(cut) %>% 
    mutate(price_carat = case_when(price > 10000 & carat < 1.5 ~ 1,
                   price <= 10000 ~ 0,
                   carat >= 1.5 ~ 0)) %>% 
    summarize(count=n(), percentage=sum(price_carat)/n())
```

The result make sense, because the better the cut the higher the price and the smaller the carat and the price/carat is higher.

The count and the percentage are pretty similar between Very Good cut and Premium cut. This difference is much smaller than the difference between Fair cut and Good cut, Premium cut and Ideal cut.


------

### G. EDA (6 points)

###     Take a look at the txhousing data set that is included with the ggplot2 package and answer these questions:

####     1. During what time period is this data from?

```{r}
table(txhousing$year,txhousing$month)
```

Time period from 2010 Jan to 2015 Jul.


####     2. How many cities are represented?

```{r}
length(unique(txhousing$city))
```

46 cities are represented.


####     3. Which city, month and year had the highest number of sales?

```{r}
tx <- txhousing %>% 
    group_by(city,year,month) 
tx[order(-tx$sales),][1,]
```

Houston year 2015 Jul has the highest number of sales (8945).


####     4. What kind of relationship do you think exists between the number of listings and the number of sales? Check your assumption and show your work.

```{r}
ggplot(data=txhousing, mapping = aes(x=listings, y=sales))+
    geom_point() +
    geom_smooth()

```

The bigger the listings the bigger the number of sales.


####     5. What proportion of sales is missing for each city?

```{r}
txhousing %>% 
    group_by(city) %>%
    mutate(missing_sales=case_when(is.na(sales) ~ 1,
                                   !is.na(sales) ~0)) %>%
    summarize(missing_sales_perc=sum(missing_sales)/n())
```


####     6. Looking at only the cities and months with greater than 500 sales:
####     • Are the distributions of the median sales price (column name median), when grouped by city, different? The same? Show your work.

```{r}
txhouse_500 <- txhousing[txhousing$sales>500,]
hist(txhouse_500$median,xlab='Overall median',main='Overall median')
mean(txhouse_500$median, na.rm = TRUE)
sd(txhouse_500$median, na.rm = TRUE)


txhouse_500_by_city <- txhouse_500 %>% filter(median != is.na(median)) %>%
    group_by(city) %>% summarize(median_new=median(median),sales_count=sum(sales))
hist(txhouse_500_by_city$median_new,xlab='Median group by City',main='Median group by City')
mean(txhouse_500_by_city$median_new, na.rm = TRUE)
sd(txhouse_500_by_city$median_new, na.rm = TRUE)

txhouse_500_by_city[order(txhouse_500_by_city$median_new),]

```

The distributions of the median sales price is not the same. The median is bigger in the by city example, and the standard deviation of median in the by city example is smaller than the sd in the overall example.

####     • Any cities that stand out that you’d want to investigate further?

I will investigate Corpus Christi and Houston.
Corpus Christi has the low sales count and low sales median. Houston has high sales count and low sales median.

####     • Why might we want to filter out all cities and months with sales less than 500?

The median may not be correct when the sample is not big enough.

### H. Git and Github (1.5 points)

